				Project Plan

Design:
New City subway authorities are performing a review on the current mass transmit system. They want to know how the subway usage pattern has evolved over the years after COVID.
Specifically, how did the total traffic pattern change?
This project will look at the total traffic in and out of the station to examine how the data change over time.

Data:
This study will use 1 week of MTA data every 6 months across 7 consecutive years. Due to change in the datafile format, data from before 2014 are not comparible with data after 2014.  
So data from 2015-2021 are used in this study. The first 5 years are used establish the pre-covid pattern, while the data from last two years are used to indicate current trend. 
The traffic counts showed a large net inflow in the years before COVID, and a large net outflow in the most recent data. The total data as well as per station inflow/outflow data are examined to see the change in pattern. 

The total inflow and outflow should be very close in any extended period of time. This is however, not the case for the data examined. 

Algorithm: 
1. Cleaning
The SCP and UNIT column of the tables are used to uniquely identify the turnstiles in question. The per period ingress and egress traffic will be generated using the traffic counters of the same machine. Then a new table is generated, to aggregate the turnstiles in the same station into a per station values.

Here, the UNIT column is used to uniquely identify a station, so the data is summed over different SCP. 

2. 
The Per audit period traffic data is checked for anomality in the various fields. Description field containing data other than "REGULAR" requires special attention. Very large 
traffic value and very large negative values are regarded as invalid and replaced with 0. Small negative values are replaced with their absolute values thus become a small positive value.
Then save results into a csv file. SQLite will read this file, and generate a new file consist of per turnstile data per week, instead of per collection period. Then data from different weeks will be merged into one large database

3.
Then additional processing is using from python to look at the data from the 12 year period. 

Tools:

Cleaning is done using pandas to read the raw text files, generate the per period traffic, and save back into a csv file to be read by SQLite, so each week of dta is saved into a file. 

The data format in the csv file is changed mm/dd/yyyy to YYYY-MM-DD to allow sorting by SQL while in the text format. 

A python program will read the database files over the 12 year period, and generate the trend of the pre-covid period, and examine the impact of the two covid years.

The station with the largest change will be identified.
 
The cleaned, aggregated data will be plotted using matplotlib to show the trends.

Conclusion:
The change in traffic pattern occurred to most of the stations. Most stations see the balance in net traffic closer to 0. In terms of net traffic, the top 70 stations account for half the change in net traffic, while the remianing 400 stations account for the other half. A list of stations that have large change in traffic, are listed in the end.


